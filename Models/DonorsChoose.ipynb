{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [ 
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel('train_final.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.drop(labels='Unnamed: 0',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "school_state                                    0\n",
       "project_grade_category                          0\n",
       "project_subject_categories                      0\n",
       "teacher_number_of_previously_posted_projects    0\n",
       "project_is_approved                             0\n",
       "                                               ..\n",
       "resource_text_work                              0\n",
       "gender                                          0\n",
       "Project_SubCategory_1                           0\n",
       "Project_SubCategory_2                           0\n",
       "Project_SubCategory_3                           0\n",
       "Length: 64, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().apply(sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for outliers in the numerical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    182080.000000\n",
       "mean         11.237055\n",
       "std          28.016086\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           2.000000\n",
       "75%           9.000000\n",
       "max         451.000000\n",
       "Name: teacher_number_of_previously_posted_projects, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['teacher_number_of_previously_posted_projects'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD4CAYAAAAZ1BptAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAVPklEQVR4nO3cf4ydV53f8fen9ibAroITMkGpbdWhWFtCtLsEK5hSVYgsiRMQzh+JlGjVWNSSVRpattoKnCKtVSBVUKsNmwqipsSNgxAmzVLFglDXcoJQJRIyIZAfZLMeAk1mk8XD2snSImDNfvvHPQOX8T0ee64942TeL+nqPs/3nOe55zlR5uPnx72pKiRJGuXvLfUAJEmnL0NCktRlSEiSugwJSVKXISFJ6lq51AM42c4999xat27dUg9Dkl5WHnnkkR9V1cTc+isuJNatW8fk5ORSD0OSXlaS/J9RdS83SZK6DAlJUpchIUnqMiQkSV3zhkSSnUkOJnliRNu/TVJJzm3rSXJrkqkkjyW5eKjvliQH2mvLUP2tSR5v29yaJK1+TpJ9rf++JGefnEOWJB2v4zmTuBPYNLeYZC3wbuDZofIVwPr22gbc1vqeA+wA3gZcAuwY+qN/W+s7u93sZ20H9lfVemB/W5ckLaJ5Q6Kqvg4cGtF0C/BhYPhnZDcDd9XAg8CqJOcDlwP7qupQVR0G9gGbWttZVfWNGvwc7V3AVUP72tWWdw3VJUmLZEH3JJK8D/jLqvrOnKbVwHND69Otdqz69Ig6wOur6gWA9n7eMcazLclkksmZmZkFHJEkaZQTDokkrwE+CvzxqOYRtVpA/YRU1e1VtaGqNkxMHPWFQUnSAi3kG9f/ELgA+E67x7wG+FaSSxicCawd6rsGeL7V3zmn/rVWXzOiP8APk5xfVS+0y1IHFzDWE7Ju+1e6bT+4+T2n+uMl6bRzwmcSVfV4VZ1XVeuqah2DP/QXV9VfAXuA69tTThuBl9qlor3AZUnObjesLwP2trYfJ9nYnmq6Hri3fdQeYPYpqC1DdUnSIjmeR2C/AHwD+O0k00m2HqP7fcAzwBTwX4F/CVBVh4CPAw+318daDeADwGfbNt8DvtrqNwPvTnKAwVNUN5/YoUmSxjXv5aaqum6e9nVDywXc0Om3E9g5oj4JXDSi/tfApfONT5J06viNa0lSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1zRsSSXYmOZjkiaHaf0zy50keS/I/kqwaarsxyVSSp5NcPlTf1GpTSbYP1S9I8lCSA0m+mOSMVj+zrU+19nUn66AlScfneM4k7gQ2zantAy6qqt8B/gK4ESDJhcC1wJvbNp9JsiLJCuDTwBXAhcB1rS/AJ4Fbqmo9cBjY2upbgcNV9UbgltZPkrSI5g2Jqvo6cGhO7X9V1ZG2+iCwpi1vBnZX1c+q6vvAFHBJe01V1TNV9XNgN7A5SYB3Afe07XcBVw3ta1dbvge4tPWXJC2Sk3FP4p8DX23Lq4HnhtqmW61Xfx3w4lDgzNZ/bV+t/aXW/yhJtiWZTDI5MzMz9gFJkgbGCokkHwWOAJ+fLY3oVguoH2tfRxerbq+qDVW1YWJi4tiDliQdt5UL3TDJFuC9wKVVNfvHexpYO9RtDfB8Wx5V/xGwKsnKdrYw3H92X9NJVgKvZc5lL0nSqbWgM4kkm4CPAO+rqp8MNe0Brm1PJl0ArAe+CTwMrG9PMp3B4Ob2nhYuDwBXt+23APcO7WtLW74auH8ojCRJi2DeM4kkXwDeCZybZBrYweBppjOBfe1e8oNV9S+q6skkdwPfZXAZ6oaq+kXbzweBvcAKYGdVPdk+4iPA7iSfAB4F7mj1O4DPJZlicAZx7Uk4XknSCZg3JKrquhHlO0bUZvvfBNw0on4fcN+I+jMMnn6aW/8pcM1845MknTp+41qS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXfOGRJKdSQ4meWKodk6SfUkOtPezWz1Jbk0yleSxJBcPbbOl9T+QZMtQ/a1JHm/b3Jokx/oMSdLiOZ4ziTuBTXNq24H9VbUe2N/WAa4A1rfXNuA2GPzBB3YAbwMuAXYM/dG/rfWd3W7TPJ8hSVok84ZEVX0dODSnvBnY1ZZ3AVcN1e+qgQeBVUnOBy4H9lXVoao6DOwDNrW2s6rqG1VVwF1z9jXqMyRJi2Sh9yReX1UvALT381p9NfDcUL/pVjtWfXpE/VifcZQk25JMJpmcmZlZ4CFJkuY62TeuM6JWC6ifkKq6vao2VNWGiYmJE91cktSx0JD4YbtURHs/2OrTwNqhfmuA5+eprxlRP9ZnSJIWyUJDYg8w+4TSFuDeofr17SmnjcBL7VLRXuCyJGe3G9aXAXtb24+TbGxPNV0/Z1+jPkOStEhWztchyReAdwLnJplm8JTSzcDdSbYCzwLXtO73AVcCU8BPgPcDVNWhJB8HHm79PlZVszfDP8DgCapXA19tL47xGZKkRTJvSFTVdZ2mS0f0LeCGzn52AjtH1CeBi0bU/3rUZ0iSFo/fuJYkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkrrGCokk/ybJk0meSPKFJK9KckGSh5IcSPLFJGe0vme29anWvm5oPze2+tNJLh+qb2q1qSTbxxmrJOnELTgkkqwG/jWwoaouAlYA1wKfBG6pqvXAYWBr22QrcLiq3gjc0vqR5MK23ZuBTcBnkqxIsgL4NHAFcCFwXesrSVok415uWgm8OslK4DXAC8C7gHta+y7gqra8ua3T2i9NklbfXVU/q6rvA1PAJe01VVXPVNXPgd2tryRpkSw4JKrqL4H/BDzLIBxeAh4BXqyqI63bNLC6La8GnmvbHmn9Xzdcn7NNry5JWiTjXG46m8G/7C8A/j7wmwwuDc1Vs5t02k60Pmos25JMJpmcmZmZb+iSpOM0zuWm3we+X1UzVfW3wJeAfwysapefANYAz7flaWAtQGt/LXBouD5nm179KFV1e1VtqKoNExMTYxySJGnYOCHxLLAxyWvavYVLge8CDwBXtz5bgHvb8p62Tmu/v6qq1a9tTz9dAKwHvgk8DKxvT0udweDm9p4xxitJOkEr5+8yWlU9lOQe4FvAEeBR4HbgK8DuJJ9otTvaJncAn0syxeAM4tq2nyeT3M0gYI4AN1TVLwCSfBDYy+DJqZ1V9eRCxytJOnELDgmAqtoB7JhTfobBk0lz+/4UuKazn5uAm0bU7wPuG2eMkqSF8xvXkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoaKySSrEpyT5I/T/JUkrcnOSfJviQH2vvZrW+S3JpkKsljSS4e2s+W1v9Aki1D9bcmebxtc2uSjDNeSdKJGfdM4k+B/1lV/wj4XeApYDuwv6rWA/vbOsAVwPr22gbcBpDkHGAH8DbgEmDHbLC0PtuGtts05nglSSdgwSGR5CzgnwJ3AFTVz6vqRWAzsKt12wVc1ZY3A3fVwIPAqiTnA5cD+6rqUFUdBvYBm1rbWVX1jaoq4K6hfUmSFsE4ZxJvAGaA/5bk0SSfTfKbwOur6gWA9n5e678aeG5o++lWO1Z9ekT9KEm2JZlMMjkzMzPGIUmSho0TEiuBi4HbquotwP/jV5eWRhl1P6EWUD+6WHV7VW2oqg0TExPHHrUk6biNExLTwHRVPdTW72EQGj9sl4po7weH+q8d2n4N8Pw89TUj6pKkRbLgkKiqvwKeS/LbrXQp8F1gDzD7hNIW4N62vAe4vj3ltBF4qV2O2gtcluTsdsP6MmBva/txko3tqabrh/YlSVoEK8fc/l8Bn09yBvAM8H4GwXN3kq3As8A1re99wJXAFPCT1peqOpTk48DDrd/HqupQW/4AcCfwauCr7SVJWiRjhURVfRvYMKLp0hF9C7ihs5+dwM4R9UngonHGKElaOL9xLUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqSusUMiyYokjyb5clu/IMlDSQ4k+WKSM1r9zLY+1drXDe3jxlZ/OsnlQ/VNrTaVZPu4Y5UknZiTcSbxIeCpofVPArdU1XrgMLC11bcCh6vqjcAtrR9JLgSuBd4MbAI+04JnBfBp4ArgQuC61leStEjGCokka4D3AJ9t6wHeBdzTuuwCrmrLm9s6rf3S1n8zsLuqflZV3wemgEvaa6qqnqmqnwO7W19J0iIZ90ziU8CHgb9r668DXqyqI219GljdllcDzwG09pda/1/W52zTqx8lybYkk0kmZ2ZmxjwkSdKsBYdEkvcCB6vqkeHyiK41T9uJ1o8uVt1eVRuqasPExMQxRi1JOhErx9j2HcD7klwJvAo4i8GZxaokK9vZwhrg+dZ/GlgLTCdZCbwWODRUnzW8Ta8uSVoECz6TqKobq2pNVa1jcOP5/qr6A+AB4OrWbQtwb1ve09Zp7fdXVbX6te3ppwuA9cA3gYeB9e1pqTPaZ+xZ6HglSSdunDOJno8Au5N8AngUuKPV7wA+l2SKwRnEtQBV9WSSu4HvAkeAG6rqFwBJPgjsBVYAO6vqyVMwXklSx0kJiar6GvC1tvwMgyeT5vb5KXBNZ/ubgJtG1O8D7jsZY5QknTi/cS1J6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkrgWHRJK1SR5I8lSSJ5N8qNXPSbIvyYH2fnarJ8mtSaaSPJbk4qF9bWn9DyTZMlR/a5LH2za3Jsk4BytJOjHjnEkcAf6oqt4EbARuSHIhsB3YX1Xrgf1tHeAKYH17bQNug0GoADuAtwGXADtmg6X12Ta03aYxxitJOkELDomqeqGqvtWWfww8BawGNgO7WrddwFVteTNwVw08CKxKcj5wObCvqg5V1WFgH7CptZ1VVd+oqgLuGtqXJGkRnJR7EknWAW8BHgJeX1UvwCBIgPNat9XAc0ObTbfaserTI+qjPn9bkskkkzMzM+MejiSpGTskkvwW8GfAH1bV3xyr64haLaB+dLHq9qraUFUbJiYm5huyJOk4jRUSSX6DQUB8vqq+1Mo/bJeKaO8HW30aWDu0+Rrg+Xnqa0bUJUmLZOVCN2xPGt0BPFVVfzLUtAfYAtzc3u8dqn8wyW4GN6lfqqoXkuwF/sPQzerLgBur6lCSHyfZyOAy1vXAf17oeMe1bvtXRtZ/cPN7FnkkkrR4FhwSwDuAfwY8nuTbrfbvGITD3Um2As8C17S2+4ArgSngJ8D7AVoYfBx4uPX7WFUdassfAO4EXg18tb0kSYtkwSFRVf+b0fcNAC4d0b+AGzr72gnsHFGfBC5a6BglSePxG9eSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUtc4vwIr+j8hDv6MuKSXP88kJEldhoQkqcuQkCR1GRKSpC5vXJ9C3tSW9HLnmYQkqcuQkCR1eblpifQuRXkZStLp5LQPiSSbgD8FVgCfraqbl3hIp5T3MSSdTk7rkEiyAvg08G5gGng4yZ6q+u7SjmxpHCtAegwWSeM4rUMCuASYqqpnAJLsBjYDyzIkFmIhwXK6M/ikxXO6h8Rq4Lmh9WngbXM7JdkGbGur/zfJ0wv8vHOBHy1w21eS03oe8slF/bjTei4WkfMw8Eqeh38wqni6h0RG1OqoQtXtwO1jf1gyWVUbxt3Py53z8CvOxYDzMLAc5+F0fwR2Glg7tL4GeH6JxiJJy87pHhIPA+uTXJDkDOBaYM8Sj0mSlo3T+nJTVR1J8kFgL4NHYHdW1ZOn8CPHvmT1CuE8/IpzMeA8DCy7eUjVUZf4JUkCTv/LTZKkJWRISJK6DIkmyaYkTyeZSrJ9qcdzKiXZmeRgkieGauck2ZfkQHs/u9WT5NY2L48luXjpRn5yJVmb5IEkTyV5MsmHWn1ZzUWSVyX5ZpLvtHn4961+QZKH2jx8sT08QpIz2/pUa1+3lOM/2ZKsSPJoki+39WU5D7MMCX7t5z+uAC4Erkty4dKO6pS6E9g0p7Yd2F9V64H9bR0Gc7K+vbYBty3SGBfDEeCPqupNwEbghvbffbnNxc+Ad1XV7wK/B2xKshH4JHBLm4fDwNbWfytwuKreCNzS+r2SfAh4amh9uc7DQFUt+xfwdmDv0PqNwI1LPa5TfMzrgCeG1p8Gzm/L5wNPt+X/Alw3qt8r7QXcy+B3wpbtXACvAb7F4JcNfgSsbPVf/j/C4GnDt7flla1flnrsJ+n41zD4h8G7gC8z+ELvspuH4ZdnEgOjfv5j9RKNZam8vqpeAGjv57X6spibdqngLcBDLMO5aJdYvg0cBPYB3wNerKojrcvwsf5yHlr7S8DrFnfEp8yngA8Df9fWX8fynIdfMiQGjuvnP5apV/zcJPkt4M+AP6yqvzlW1xG1V8RcVNUvqur3GPxL+hLgTaO6tfdX5DwkeS9wsKoeGS6P6PqKnoe5DIkBf/4DfpjkfID2frDVX9Fzk+Q3GATE56vqS628LOcCoKpeBL7G4B7NqiSzX7gdPtZfzkNrfy1waHFHekq8A3hfkh8AuxlccvoUy28efo0hMeDPfwyOd0tb3sLg+vxs/fr2ZM9G4KXZSzEvd0kC3AE8VVV/MtS0rOYiyUSSVW351cDvM7hx+wBwdes2dx5m5+dq4P5qF+ZfzqrqxqpaU1XrGPwNuL+q/oBlNg9HWeqbIqfLC7gS+AsG12I/utTjOcXH+gXgBeBvGfxraCuDa6n7gQPt/ZzWNwye/Poe8DiwYanHfxLn4Z8wuDzwGPDt9rpyuc0F8DvAo20engD+uNXfAHwTmAL+O3Bmq7+qrU+19jcs9TGcgjl5J/Dl5T4PVeXPckiS+rzcJEnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSuv4/nZ6S2DOfrJwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train['teacher_number_of_previously_posted_projects'], bins=range(min(train['teacher_number_of_previously_posted_projects']), max(train['teacher_number_of_previously_posted_projects']) + 10, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gender = {'Mr.':'Male', 'Mrs.':'Female', 'Ms.':'Female'}\n",
    "# train['gender'] = train['teacher_prefix'].map(gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['gender'].fillna('Not Provided', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from scikitplot.metrics import plot_lift_curve\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support, roc_curve, auc, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, neighbors\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from dtreeviz.trees import *\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treating the columns and making a dataset out of required columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['school_state', 'project_grade_category', 'project_subject_categories',\n",
       "       'teacher_number_of_previously_posted_projects', 'project_is_approved',\n",
       "       'items', 'quantity', 'price', 'total_price', 'min_quantity',\n",
       "       'min_price', 'min_total_price', 'max_quantity', 'max_price',\n",
       "       'max_total_price', 'mean_quantity', 'mean_price', 'mean_total_price',\n",
       "       'Year', 'Month', 'Weekday', 'Hour', 'Month_Day', 'Year_Day',\n",
       "       'essay1_len', 'essay2_len', 'essay3_len', 'essay4_len', 'title_len',\n",
       "       'char_count', 'word_count', 'word_density', 'punctuation_count',\n",
       "       'title_word_count', 'upper_case_word_count', 'stopword_count',\n",
       "       'polarity', 'subjectivity', 'title_polarity', 'title_subjectivity',\n",
       "       'article_text_classroom', 'article_text_help', 'article_text_learn',\n",
       "       'article_text_learning', 'article_text_need', 'article_text_reading',\n",
       "       'article_text_school', 'article_text_students', 'article_text_use',\n",
       "       'article_text_work', 'resource_text_classroom', 'resource_text_help',\n",
       "       'resource_text_learn', 'resource_text_learning', 'resource_text_need',\n",
       "       'resource_text_reading', 'resource_text_school',\n",
       "       'resource_text_students', 'resource_text_use', 'resource_text_work',\n",
       "       'gender', 'Project_SubCategory_1', 'Project_SubCategory_2',\n",
       "       'Project_SubCategory_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>project_subject_categories</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>items</th>\n",
       "      <th>quantity</th>\n",
       "      <th>price</th>\n",
       "      <th>total_price</th>\n",
       "      <th>min_quantity</th>\n",
       "      <th>min_price</th>\n",
       "      <th>min_total_price</th>\n",
       "      <th>max_quantity</th>\n",
       "      <th>max_price</th>\n",
       "      <th>max_total_price</th>\n",
       "      <th>mean_quantity</th>\n",
       "      <th>mean_price</th>\n",
       "      <th>mean_total_price</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Month_Day</th>\n",
       "      <th>Year_Day</th>\n",
       "      <th>essay1_len</th>\n",
       "      <th>essay2_len</th>\n",
       "      <th>essay3_len</th>\n",
       "      <th>essay4_len</th>\n",
       "      <th>title_len</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "      <th>stopword_count</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>title_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>article_text_classroom</th>\n",
       "      <th>article_text_help</th>\n",
       "      <th>article_text_learn</th>\n",
       "      <th>article_text_learning</th>\n",
       "      <th>article_text_need</th>\n",
       "      <th>article_text_reading</th>\n",
       "      <th>article_text_school</th>\n",
       "      <th>article_text_students</th>\n",
       "      <th>article_text_use</th>\n",
       "      <th>article_text_work</th>\n",
       "      <th>resource_text_classroom</th>\n",
       "      <th>resource_text_help</th>\n",
       "      <th>resource_text_learn</th>\n",
       "      <th>resource_text_learning</th>\n",
       "      <th>resource_text_need</th>\n",
       "      <th>resource_text_reading</th>\n",
       "      <th>resource_text_school</th>\n",
       "      <th>resource_text_students</th>\n",
       "      <th>resource_text_use</th>\n",
       "      <th>resource_text_work</th>\n",
       "      <th>gender</th>\n",
       "      <th>Project_SubCategory_1</th>\n",
       "      <th>Project_SubCategory_2</th>\n",
       "      <th>Project_SubCategory_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>299.98</td>\n",
       "      <td>899.94</td>\n",
       "      <td>3</td>\n",
       "      <td>149.99</td>\n",
       "      <td>449.97</td>\n",
       "      <td>3</td>\n",
       "      <td>149.99</td>\n",
       "      <td>449.97</td>\n",
       "      <td>3.0</td>\n",
       "      <td>149.990</td>\n",
       "      <td>449.970</td>\n",
       "      <td>2016</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>323</td>\n",
       "      <td>967</td>\n",
       "      <td>805</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>1775</td>\n",
       "      <td>312</td>\n",
       "      <td>5.670927</td>\n",
       "      <td>40</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>151</td>\n",
       "      <td>0.213402</td>\n",
       "      <td>0.391136</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150877</td>\n",
       "      <td>0.290453</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.165534</td>\n",
       "      <td>0.208328</td>\n",
       "      <td>0.346046</td>\n",
       "      <td>0.801055</td>\n",
       "      <td>0.177267</td>\n",
       "      <td>0.170913</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150877</td>\n",
       "      <td>0.290453</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.165534</td>\n",
       "      <td>0.208328</td>\n",
       "      <td>0.346046</td>\n",
       "      <td>0.801055</td>\n",
       "      <td>0.177267</td>\n",
       "      <td>0.170913</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>20.00</td>\n",
       "      <td>400.00</td>\n",
       "      <td>20</td>\n",
       "      <td>20.00</td>\n",
       "      <td>400.00</td>\n",
       "      <td>20</td>\n",
       "      <td>20.00</td>\n",
       "      <td>400.00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.000</td>\n",
       "      <td>400.000</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>26</td>\n",
       "      <td>116</td>\n",
       "      <td>587</td>\n",
       "      <td>639</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>1229</td>\n",
       "      <td>190</td>\n",
       "      <td>6.434555</td>\n",
       "      <td>38</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>79</td>\n",
       "      <td>0.192889</td>\n",
       "      <td>0.597111</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.210075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.803034</td>\n",
       "      <td>0.557678</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.210075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.803034</td>\n",
       "      <td>0.557678</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>469.99</td>\n",
       "      <td>469.99</td>\n",
       "      <td>1</td>\n",
       "      <td>469.99</td>\n",
       "      <td>469.99</td>\n",
       "      <td>1</td>\n",
       "      <td>469.99</td>\n",
       "      <td>469.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>469.990</td>\n",
       "      <td>469.990</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>761</td>\n",
       "      <td>546</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>1310</td>\n",
       "      <td>234</td>\n",
       "      <td>5.574468</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>103</td>\n",
       "      <td>0.353888</td>\n",
       "      <td>0.534450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075981</td>\n",
       "      <td>0.746628</td>\n",
       "      <td>0.159703</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190271</td>\n",
       "      <td>0.605624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075981</td>\n",
       "      <td>0.746628</td>\n",
       "      <td>0.159703</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190271</td>\n",
       "      <td>0.605624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>684.47</td>\n",
       "      <td>684.47</td>\n",
       "      <td>1</td>\n",
       "      <td>18.95</td>\n",
       "      <td>18.95</td>\n",
       "      <td>1</td>\n",
       "      <td>354.99</td>\n",
       "      <td>354.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>136.894</td>\n",
       "      <td>136.894</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>225</td>\n",
       "      <td>1201</td>\n",
       "      <td>1209</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>2413</td>\n",
       "      <td>386</td>\n",
       "      <td>6.235142</td>\n",
       "      <td>77</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>188</td>\n",
       "      <td>0.175880</td>\n",
       "      <td>0.416224</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.165417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.148435</td>\n",
       "      <td>0.181486</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.695556</td>\n",
       "      <td>0.658688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.165417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.148435</td>\n",
       "      <td>0.181486</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.695556</td>\n",
       "      <td>0.658688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>355.50</td>\n",
       "      <td>711.00</td>\n",
       "      <td>2</td>\n",
       "      <td>355.50</td>\n",
       "      <td>711.00</td>\n",
       "      <td>2</td>\n",
       "      <td>355.50</td>\n",
       "      <td>711.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>355.500</td>\n",
       "      <td>711.000</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>219</td>\n",
       "      <td>451</td>\n",
       "      <td>556</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>1010</td>\n",
       "      <td>185</td>\n",
       "      <td>5.430108</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>0.285417</td>\n",
       "      <td>0.557192</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.218182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.229298</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.948588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.218182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.229298</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.948588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   school_state  project_grade_category  project_subject_categories  \\\n",
       "0            33                       3                          24   \n",
       "1            10                       0                          42   \n",
       "2            44                       0                          36   \n",
       "3            27                       0                           8   \n",
       "4             4                       1                           8   \n",
       "\n",
       "   teacher_number_of_previously_posted_projects  project_is_approved  items  \\\n",
       "0                                            26                    1      2   \n",
       "1                                             1                    0      1   \n",
       "2                                             5                    1      1   \n",
       "3                                            16                    0      5   \n",
       "4                                            42                    1      1   \n",
       "\n",
       "   quantity   price  total_price  min_quantity  min_price  min_total_price  \\\n",
       "0         6  299.98       899.94             3     149.99           449.97   \n",
       "1        20   20.00       400.00            20      20.00           400.00   \n",
       "2         1  469.99       469.99             1     469.99           469.99   \n",
       "3         5  684.47       684.47             1      18.95            18.95   \n",
       "4         2  355.50       711.00             2     355.50           711.00   \n",
       "\n",
       "   max_quantity  max_price  max_total_price  mean_quantity  mean_price  \\\n",
       "0             3     149.99           449.97            3.0     149.990   \n",
       "1            20      20.00           400.00           20.0      20.000   \n",
       "2             1     469.99           469.99            1.0     469.990   \n",
       "3             1     354.99           354.99            1.0     136.894   \n",
       "4             2     355.50           711.00            2.0     355.500   \n",
       "\n",
       "   mean_total_price  Year  Month  Weekday  Hour  Month_Day  Year_Day  \\\n",
       "0           449.970  2016     11        4    14         18       323   \n",
       "1           400.000  2017      4        2    15         26       116   \n",
       "2           469.990  2017      1        6    22          1         1   \n",
       "3           136.894  2016      8        4    15         12       225   \n",
       "4           711.000  2016      8        5     9          6       219   \n",
       "\n",
       "   essay1_len  essay2_len  essay3_len  essay4_len  title_len  char_count  \\\n",
       "0         967         805           0           0         24        1775   \n",
       "1         587         639           0           0         22        1229   \n",
       "2         761         546           0           0         21        1310   \n",
       "3        1201        1209           0           0         72        2413   \n",
       "4         451         556           0           0         48        1010   \n",
       "\n",
       "   word_count  word_density  punctuation_count  title_word_count  \\\n",
       "0         312      5.670927                 40                21   \n",
       "1         190      6.434555                 38                15   \n",
       "2         234      5.574468                 26                26   \n",
       "3         386      6.235142                 77                31   \n",
       "4         185      5.430108                 15                13   \n",
       "\n",
       "   upper_case_word_count  stopword_count  polarity  subjectivity  \\\n",
       "0                      5             151  0.213402      0.391136   \n",
       "1                      3              79  0.192889      0.597111   \n",
       "2                      4             103  0.353888      0.534450   \n",
       "3                      4             188  0.175880      0.416224   \n",
       "4                      0              98  0.285417      0.557192   \n",
       "\n",
       "   title_polarity  title_subjectivity  article_text_classroom  \\\n",
       "0        0.333333            0.666667                0.000000   \n",
       "1        0.300000            0.750000                0.000000   \n",
       "2        0.000000            0.000000                0.075981   \n",
       "3        0.500000            0.500000                0.000000   \n",
       "4        0.183333            0.350000                0.218182   \n",
       "\n",
       "   article_text_help  article_text_learn  article_text_learning  \\\n",
       "0           0.150877            0.290453               0.000000   \n",
       "1           0.210075            0.000000               0.000000   \n",
       "2           0.746628            0.159703               0.000000   \n",
       "3           0.165417            0.000000               0.148435   \n",
       "4           0.000000            0.229298               0.000000   \n",
       "\n",
       "   article_text_need  article_text_reading  article_text_school  \\\n",
       "0           0.165534              0.208328             0.346046   \n",
       "1           0.000000              0.000000             0.803034   \n",
       "2           0.091018              0.000000             0.190271   \n",
       "3           0.181486              0.000000             0.695556   \n",
       "4           0.000000              0.000000             0.000000   \n",
       "\n",
       "   article_text_students  article_text_use  article_text_work  \\\n",
       "0               0.801055          0.177267           0.170913   \n",
       "1               0.557678          0.000000           0.000000   \n",
       "2               0.605624          0.000000           0.000000   \n",
       "3               0.658688          0.000000           0.000000   \n",
       "4               0.948588          0.000000           0.000000   \n",
       "\n",
       "   resource_text_classroom  resource_text_help  resource_text_learn  \\\n",
       "0                 0.000000            0.150877             0.290453   \n",
       "1                 0.000000            0.210075             0.000000   \n",
       "2                 0.075981            0.746628             0.159703   \n",
       "3                 0.000000            0.165417             0.000000   \n",
       "4                 0.218182            0.000000             0.229298   \n",
       "\n",
       "   resource_text_learning  resource_text_need  resource_text_reading  \\\n",
       "0                0.000000            0.165534               0.208328   \n",
       "1                0.000000            0.000000               0.000000   \n",
       "2                0.000000            0.091018               0.000000   \n",
       "3                0.148435            0.181486               0.000000   \n",
       "4                0.000000            0.000000               0.000000   \n",
       "\n",
       "   resource_text_school  resource_text_students  resource_text_use  \\\n",
       "0              0.346046                0.801055           0.177267   \n",
       "1              0.803034                0.557678           0.000000   \n",
       "2              0.190271                0.605624           0.000000   \n",
       "3              0.695556                0.658688           0.000000   \n",
       "4              0.000000                0.948588           0.000000   \n",
       "\n",
       "   resource_text_work  gender  Project_SubCategory_1  Project_SubCategory_2  \\\n",
       "0            0.170913       0                     16                     -1   \n",
       "1            0.000000       0                     23                     26   \n",
       "2            0.000000       0                      0                     17   \n",
       "3            0.000000       1                     14                     -1   \n",
       "4            0.000000       1                     14                     -1   \n",
       "\n",
       "   Project_SubCategory_3  \n",
       "0                     -1  \n",
       "1                     -1  \n",
       "2                     -1  \n",
       "3                     -1  \n",
       "4                     -1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns',500)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cols = ['school_state', 'project_grade_category', 'project_subject_categories',\n",
    "       'teacher_number_of_previously_posted_projects',\n",
    "       'items', 'quantity', 'price', 'total_price', 'min_quantity',\n",
    "       'min_price', 'min_total_price', 'max_quantity', 'max_price',\n",
    "       'max_total_price', 'mean_quantity', 'mean_price', 'mean_total_price',\n",
    "       'Year', 'Month', 'Weekday', 'Hour', 'Month_Day', 'Year_Day',\n",
    "       'essay1_len', 'essay2_len', 'essay3_len', 'essay4_len', 'title_len',\n",
    "       'char_count', 'word_count', 'word_density', 'punctuation_count',\n",
    "       'title_word_count', 'upper_case_word_count', 'stopword_count',\n",
    "       'polarity', 'subjectivity', 'title_polarity', 'title_subjectivity',\n",
    "       'article_text_classroom', 'article_text_help', 'article_text_learn',\n",
    "       'article_text_learning', 'article_text_need', 'article_text_reading',\n",
    "       'article_text_school', 'article_text_students', 'article_text_use',\n",
    "       'article_text_work', 'resource_text_classroom', 'resource_text_help',\n",
    "       'resource_text_learn', 'resource_text_learning', 'resource_text_need',\n",
    "       'resource_text_reading', 'resource_text_school',\n",
    "       'resource_text_students', 'resource_text_use', 'resource_text_work',\n",
    "       'gender', 'Project_SubCategory_1', 'Project_SubCategory_2',\n",
    "       'Project_SubCategory_3']\n",
    "\n",
    "y_cols = ['project_is_approved']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = train[x_cols]\n",
    "y_all = train[y_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of observations is  182080\n",
      "The number of features is  63\n",
      "\n",
      "\n",
      "The features of the dataset are:  Index(['school_state', 'project_grade_category', 'project_subject_categories',\n",
      "       'teacher_number_of_previously_posted_projects', 'items', 'quantity',\n",
      "       'price', 'total_price', 'min_quantity', 'min_price', 'min_total_price',\n",
      "       'max_quantity', 'max_price', 'max_total_price', 'mean_quantity',\n",
      "       'mean_price', 'mean_total_price', 'Year', 'Month', 'Weekday', 'Hour',\n",
      "       'Month_Day', 'Year_Day', 'essay1_len', 'essay2_len', 'essay3_len',\n",
      "       'essay4_len', 'title_len', 'char_count', 'word_count', 'word_density',\n",
      "       'punctuation_count', 'title_word_count', 'upper_case_word_count',\n",
      "       'stopword_count', 'polarity', 'subjectivity', 'title_polarity',\n",
      "       'title_subjectivity', 'article_text_classroom', 'article_text_help',\n",
      "       'article_text_learn', 'article_text_learning', 'article_text_need',\n",
      "       'article_text_reading', 'article_text_school', 'article_text_students',\n",
      "       'article_text_use', 'article_text_work', 'resource_text_classroom',\n",
      "       'resource_text_help', 'resource_text_learn', 'resource_text_learning',\n",
      "       'resource_text_need', 'resource_text_reading', 'resource_text_school',\n",
      "       'resource_text_students', 'resource_text_use', 'resource_text_work',\n",
      "       'gender', 'Project_SubCategory_1', 'Project_SubCategory_2',\n",
      "       'Project_SubCategory_3'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "The target variable of the dataset is: project_is_approved\n"
     ]
    }
   ],
   "source": [
    "## Dataset dimensions\n",
    "n_obsv, n_feat = x_all.shape\n",
    "\n",
    "print('The number of observations is ', n_obsv)\n",
    "print('The number of features is ', n_feat)\n",
    "print('\\n')\n",
    "\n",
    "# features = names[0:len(names)-1]\n",
    "# target = names[len(names)-1]\n",
    "print('The features of the dataset are: ', x_all.columns)\n",
    "print('\\n')\n",
    "print('The target variable of the dataset is:', y_cols[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_numeric = x_all['teacher_number_of_previously_posted_projects']\n",
    "# x_cat = x_all.drop(['teacher_number_of_previously_posted_projects'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_cat_ohe = pd.get_dummies(x_cat)\n",
    "# x_all = pd.concat([x_cat_ohe, x_numeric], axis=1)\n",
    "\n",
    "# ## Splitting data into train and test sets (using all features label encoded)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(x_all, y_all, test_size = 0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import label encoder \n",
    "# from sklearn import preprocessing \n",
    "  \n",
    "# # label_encoder object knows how to understand word labels. \n",
    "# label_encoder = preprocessing.LabelEncoder() \n",
    "  \n",
    "# # Encode labels in column 'species'. \n",
    "# df['species']= label_encoder.fit_transform(x_cat) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = train.sample(frac=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all_sample = train_sample[x_cols]\n",
    "y_all_sample = train_sample[y_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Splitting data into train and test sets (using all features label encoded)\n",
    "X_train_sample, X_test_sample, y_train_sample, y_test_sample = train_test_split(x_all_sample, y_all_sample, test_size = 0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    15495\n",
       "0     2713\n",
       "Name: project_is_approved, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_all_sample['project_is_approved'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8691 12417]\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=12, ratio = 0.7, k_neighbors=3)\n",
    "x_res, y_res = sm.fit_sample(X_train_sample, y_train_sample)\n",
    "print(np.bincount(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_parameters = {'kernel': ['rbf', 'linear'], 'gamma': [0.1, 0.5, 1], 'C': [1, 10, 50]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding best parameters for f1\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "print('Finding best parameters for f1')\n",
    "clf = RandomizedSearchCV(svm.SVC(), hyper_parameters, cv=5,\n",
    "                   scoring='f1', n_jobs=-1)\n",
    "clf.fit(X_train_sample, y_train_sample)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='rbf', gamma=0.1, C=50)\n",
    "clf = clf.fit(x_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3642"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       564\n",
      "           1       0.85      1.00      0.92      3078\n",
      "\n",
      "    accuracy                           0.85      3642\n",
      "   macro avg       0.42      0.50      0.46      3642\n",
      "weighted avg       0.71      0.85      0.77      3642\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_sample, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building bags of KNN classifiers and running grid-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_params = {'n_neighbors':list(range(5,16)), 'weights':['uniform','distance']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_knn = KNeighborsClassifier()\n",
    "# clf_lr = linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bag = RandomizedSearchCV(BaggingClassifier(base_estimator=clf_knn, n_estimators=10, max_samples=0.7),\n",
    "                        param_grid=knn_params, cv=5, n_jobs=-1, scoring='f1')\n",
    "\n",
    "model_bag.fit(X_train_sample,y_train_sample)\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(model_bag.best_params_)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Decision tree classifier with ADA Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassfier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_params = {'max_depth':[5,10,15], 'min_samples_leaf':[15,20,25,30]}\n",
    "dtc = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = RandomizedSearchCV(AdaBoostClassifier(n_estimators = 30, base_estimator = dtc, learning_rate = 0.7), \\\n",
    "                         param_grid = dtc_params, cv=5,n_jobs=-1,scoring='f1')\n",
    "abc.fit(x_res, y_res)\n",
    "print(\"Best parameters set found :\")\n",
    "print()\n",
    "print(model_bag.best_params_)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lauren's codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree, linear_model, neighbors, datasets, svm, metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, GridSearchCV, KFold, StratifiedKFold\n",
    "from sklearn.linear_model import SGDClassifier, LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_recall_curve, average_precision_score, roc_curve, auc, confusion_matrix, classification_report, mean_absolute_error, mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(xTrain,yTrain,xTest,yTest):\n",
    "    # Define decision tree\n",
    "    tree_clf = tree.DecisionTreeClassifier()\n",
    "    p_grid = dict(max_depth = list(range(10,21,5)), min_samples_leaf=list(range(30,36,5)),criterion = [\"entropy\"])\n",
    "    \n",
    "    # Arrays to store scores - 10 is the number of random trials in\n",
    "    # the cross validation\n",
    "    non_nested_scores = np.zeros(10)\n",
    "    nested_scores = np.zeros(10)\n",
    "    \n",
    "    # Loop for each trial\n",
    "    for trial in range(10):\n",
    "        # Choose cross-validation techniques for the inner and outer loops\n",
    "        # independently of the dataset.\n",
    "        # E.g \"LabelKFold\", \"LeaveOneOut\", \"LeaveOneLabelOut\", etc.\n",
    "        inner_cv = KFold(n_splits = 4, shuffle = True, random_state = trial)\n",
    "        outer_cv = KFold(n_splits = 4, shuffle = True, random_state = trial)\n",
    "        # Non_nested parameter search and scoring\n",
    "        clf = GridSearchCV(estimator = tree_clf, param_grid = p_grid, cv = inner_cv)\n",
    "        clf.fit(xTrain, yTrain)\n",
    "        non_nested_scores[trial] = clf.best_score_\n",
    "        # Nested CV with parameter optimization\n",
    "        nested_score = cross_val_score(clf, X=xTrain, y=yTrain, cv=outer_cv)\n",
    "        nested_scores[trial] = nested_score.mean()\n",
    "    \n",
    "    score_difference = non_nested_scores - nested_scores\n",
    "    print(\"Average difference of {0:6f} with std. dev. of {1:6f}.\".format(score_difference.mean(), score_difference.std()))\n",
    "    \n",
    "    print(clf.best_score_) # the best accuracy score amongst all the possible models\n",
    "    print(clf.best_params_) # this helps to show which specific set of parameters were chosen as the best model\n",
    "    print(clf.best_estimator_) # this helps to get the best estimator \n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = clf.predict(xTest)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(yTest, y_pred, pos_label=1)\n",
    "    print(\"The AUC is:\", metrics.auc(fpr, tpr))\n",
    "    return\n",
    "\n",
    "'''\n",
    "The code below is for K - Nearest Neighbors\n",
    "'''\n",
    "def KNN(xTrain,yTrain,xTest,yTest):\n",
    "    # Define KNN\n",
    "    knn_clf = KNeighborsClassifier()\n",
    "    p_grid = dict(n_neighbors = list(range(1,31)), weights = [\"uniform\", \"distance\"])\n",
    "    \n",
    "    # Arrays to store scores - 10 is the number of random trials in\n",
    "    # the cross validation\n",
    "    non_nested_scores = np.zeros(10)\n",
    "    nested_scores = np.zeros(10)\n",
    "    \n",
    "    # Loop for each trial\n",
    "    for trial in range(10):\n",
    "        # Choose cross-validation techniques for the inner and outer loops,\n",
    "        # independently of the dataset.\n",
    "        # E.g \"LabelKFold\", \"LeaveOneOut\", \"LeaveOneLabelOut\", etc.\n",
    "        inner_cv = KFold(n_splits = 4, shuffle = True, random_state = trial)\n",
    "        outer_cv = KFold(n_splits = 4, shuffle = True, random_state = trial)\n",
    "        # Non_nested parameter search and scoring\n",
    "        clf = GridSearchCV(estimator = knn_clf, param_grid = p_grid, cv = inner_cv)\n",
    "        clf.fit(xTrain, yTrain)\n",
    "        non_nested_scores[trial] = clf.best_score_\n",
    "        # Nested CV with parameter optimization\n",
    "        nested_score = cross_val_score(clf, X=xTrain, y=yTrain, cv=outer_cv)\n",
    "        nested_scores[trial] = nested_score.mean()\n",
    "    \n",
    "    score_difference = non_nested_scores - nested_scores\n",
    "    print(\"Average difference of {0:6f} with std. dev. of {1:6f}.\".format(score_difference.mean(), score_difference.std()))\n",
    "    \n",
    "    print(clf.best_score_) # the best accuracy score amongst all the possible models\n",
    "    print(clf.best_params_) # this helps to show which specific set of parameters were chosen as the best model\n",
    "    print(clf.best_estimator_) # this helps to get the best estimator \n",
    "    \n",
    "    #Predict the response for test dataset\n",
    "    y_pred = clf.predict(xTest)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(yTest, y_pred, pos_label=2)\n",
    "    print(\"The AUC is:\", metrics.auc(fpr, tpr))\n",
    "    return\n",
    "\n",
    "'''\n",
    "The code below is for logistic regression\n",
    "'''\n",
    "def log_reg(xTrain,yTrain,xTest,yTest):\n",
    "    # Define logit\n",
    "    logit_clf = linear_model.LogisticRegression()\n",
    "    p_grid = dict(C = [0.001, 0.01, 0.1, 1, 10], penalty = [\"l1\" or \"l2\"])\n",
    "    \n",
    "    # Arrays to store scores - 10 is the number of random trials in\n",
    "    # the cross validation\n",
    "    non_nested_scores = np.zeros(10)\n",
    "    nested_scores = np.zeros(10)\n",
    "    \n",
    "    # Loop for each trial\n",
    "    for trial in range(10):\n",
    "        # Choose cross-validation techniques for the inner and outer loops,\n",
    "        # independently of the dataset.\n",
    "        # E.g \"LabelKFold\", \"LeaveOneOut\", \"LeaveOneLabelOut\", etc.\n",
    "        inner_cv = KFold(n_splits = 4, shuffle = True, random_state = trial)\n",
    "        outer_cv = KFold(n_splits = 4, shuffle = True, random_state = trial)\n",
    "        # Non_nested parameter search and scoring\n",
    "        clf = GridSearchCV(estimator = logit_clf, param_grid = p_grid, cv = inner_cv)\n",
    "        clf.fit(xTrain, yTrain)\n",
    "        non_nested_scores[trial] = clf.best_score_\n",
    "        # Nested CV with parameter optimization\n",
    "        nested_score = cross_val_score(clf, X=xTrain, y=yTrain, cv=outer_cv)\n",
    "        nested_scores[trial] = nested_score.mean()\n",
    "    \n",
    "    score_difference = non_nested_scores - nested_scores\n",
    "    print(\"Average difference of {0:6f} with std. dev. of {1:6f}.\".format(score_difference.mean(), score_difference.std()))\n",
    "    \n",
    "    print(clf.best_score_) # the best accuracy score amongst all the possible models\n",
    "    print(clf.best_params_) # this helps to show which specific set of parameters were chosen as the best model\n",
    "    print(clf.best_estimator_) # this helps to get the best estimator\n",
    "    \n",
    "    #Predict the response for test dataset\n",
    "    y_pred = clf.predict(xTest)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(yTest, y_pred, pos_label=2)\n",
    "    print(\"The AUC is:\", metrics.auc(fpr, tpr))\n",
    "    return\n",
    "\n",
    "'''\n",
    "The code below is for Naive Bayes\n",
    "'''\n",
    "def NB(xTrain,yTrain,xTest,yTest):\n",
    "    #Create a Gaussian Classifier\n",
    "    clf = GaussianNB()  \n",
    "    clf.fit(xTrain, yTrain)        \n",
    "    \n",
    "    #Predict the response for test dataset\n",
    "    y_pred = clf.predict(xTest)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(yTest, y_pred, pos_label=2)\n",
    "    print(\"The AUC is:\", metrics.auc(fpr, tpr))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average difference of 0.001199 with std. dev. of 0.001621.\n",
      "0.8180784536668562\n",
      "{'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 30}\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=20,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=30, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')\n",
      "The AUC is: 0.5449138014460896\n"
     ]
    }
   ],
   "source": [
    "decision_tree(x_res, y_res, X_test_sample, y_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN(xTrain,yTrain,xTest,yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg(xTrain,yTrain,xTest,yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB(xTrain,yTrain,xTest,yTest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
